train_losses: [4.21233293528447, 3.8491056544701463, 3.604834176085489, 3.389192148242765, 3.1787467204091495, 2.9720864789870083, 2.754465719623029, 2.5543789076988044, 2.368203721387917, 2.201129883451535, 2.067128414997969, 1.929717616351974, 1.790834039068588, 1.6600169577561985, 1.543122411079114, 1.4214232099025756, 1.3044772178620634, 1.172029942502756, 1.051748683995298, 0.929795655295672, 0.814123599120723, 0.6910770696294887, 0.5989472821850301, 0.5077344138756432, 0.43192017726276233, 0.3698073551249321, 0.30842934038175646, 0.2714131125022688, 0.2526107503248907, 0.23635544138186423, 0.20591859090739809, 0.17002134389051085, 0.16502598114788075, 0.1507532097723173, 0.17017012958407707, 0.1675526814349472, 0.14721689550468073, 0.12818129086281027, 0.11674922352175579, 0.1266942499467479, 0.11940994206101388, 0.1257636298037246, 0.12508578441293952, 0.10689360206313145, 0.09248800336590508, 0.0921377366708825, 0.10442197181837028, 0.10783453158024327, 0.10368323714836784, 0.09499391699043076, 0.09051281808282408, 0.08779448500412809, 0.08279667485057546, 0.08661829665912997, 0.08277305587649803, 0.08233402147793861, 0.06518495518266393, 0.07065146626985591, 0.0853058907305798, 0.08531446758267063, 0.07181033105267894, 0.08643444148761689, 0.07613173787913206, 0.06225327768689379, 0.06764626119028577, 0.06686430465420494, 0.05822009725205581, 0.06434526136788109, 0.07878868987836192, 0.0702668592914977, 0.06029721040307256, 0.05828213927043063, 0.05119764263196217, 0.06113179878372213, 0.06115499555188067, 0.05925727942410637, 0.05273977108537922, 0.06157713898402803, 0.057521107613735495, 0.05709178048326536, 0.05307899268768023, 0.05153149083885543, 0.050148020879558435, 0.052867614630790774, 0.05872924178552902, 0.05773835609216824, 0.04664810119515947, 0.04429025881830841, 0.062085986199319515, 0.052991256408412436, 0.058133078686645266, 0.05564617909148069, 0.0479524921640144, 0.052761938229984484, 0.05472693199058399, 0.04473726555009556, 0.04028874031408592, 0.050037063179475726, 0.059783980095535136, 0.04946869471922631]
test_losses: [3.9802279457092284, 3.729229399871826, 3.480429292678833, 3.3510823459625243, 3.1568548191070556, 2.8846481925964356, 2.706663468170166, 2.531078652572632, 2.383106954956055, 2.2732719497680662, 2.150492751312256, 2.075600313949585, 2.0163061586380007, 1.9375937747955323, 1.8721100395202637, 1.8523027156829834, 1.8251616970062257, 1.768179563331604, 1.7965169668197631, 1.7860840709686279, 1.7999368642807008, 1.8289041776657105, 1.839992046737671, 1.8912684173583985, 1.9080666620254516, 1.9757208854675292, 2.0001684492111207, 2.0502874794006347, 2.093742250061035, 2.083628918647766, 2.126431568336487, 2.1724716007232665, 2.190189029121399, 2.239642604637146, 2.206556583404541, 2.2048376947402955, 2.2007550006866454, 2.2039815160751344, 2.223724482536316, 2.237031833267212, 2.2403668983459473, 2.204331194114685, 2.2357839504241945, 2.2292763092041015, 2.2108296031951906, 2.263800433921814, 2.2738155809402465, 2.247045108795166, 2.272706170845032, 2.29263135471344, 2.2802504285812377, 2.275298861694336, 2.2981280811309817, 2.326329557991028, 2.2682479885101317, 2.2922865463256836, 2.2954031204223635, 2.284393476486206, 2.3367644538879393, 2.3414240827560424, 2.3318890369415284, 2.2813305999755857, 2.2883538890838624, 2.312826402282715, 2.316249942779541, 2.3045873142242432, 2.3053557886123657, 2.3326758598327637, 2.2781723966598513, 2.3459328359603884, 2.323355451583862, 2.259385290145874, 2.385954416847229, 2.3785207052230835, 2.3672526626586916, 2.2645924823760986, 2.350754005241394, 2.3376792930603028, 2.343254430961609, 2.3910546016693117, 2.327798247909546, 2.3658822927474974, 2.3542061555862426, 2.3237024991989137, 2.3838855867385864, 2.3216294944763183, 2.354258906364441, 2.395946996498108, 2.3327611639022825, 2.368727681541443, 2.3158037158966063, 2.3029944822311403, 2.310316367340088, 2.309151834487915, 2.304883723258972, 2.3468464723587035, 2.384712422943115, 2.377375918006897, 2.3847085868835447, 2.3643118852615355]
train_accuracies: [8.218, 12.066, 16.792, 19.804, 24.752, 29.838, 33.07, 37.822, 42.11, 46.01, 49.804, 52.59, 56.222, 58.598, 62.13, 65.864, 68.752, 73.41, 75.908, 79.35, 82.328, 85.838, 88.402, 90.018, 92.376, 93.368, 94.252, 95.218, 95.526, 96.046, 96.598, 97.248, 97.462, 97.108, 97.504, 97.342, 98.14, 97.982, 98.104, 97.922, 97.852, 98.128, 98.178, 98.472, 98.866, 98.364, 97.988, 98.55, 98.374, 98.64, 98.448, 98.952, 98.758, 98.642, 98.784, 98.994, 99.078, 98.834, 98.196, 98.916, 98.768, 98.44, 98.986, 98.864, 99.14, 99.15, 99.198, 98.774, 98.842, 99.142, 98.974, 99.32, 99.034, 98.946, 98.976, 99.262, 98.85, 99.104, 99.256, 98.996, 99.108, 99.082, 99.33, 99.264, 98.896, 99.144, 99.364, 99.058, 99.252, 98.948, 99.118, 99.254, 99.196, 99.15, 99.276, 99.422, 99.22, 99.128, 98.842, 99.346]
test_accuracies: [8.21, 11.83, 16.38, 19.22, 23.55, 28.28, 30.81, 35.12, 37.32, 40.51, 42.99, 44.67, 46.58, 47.65, 49.22, 49.8, 50.7, 51.54, 50.99, 51.88, 51.96, 51.41, 51.7, 51.43, 51.76, 50.87, 50.8, 50.85, 51.28, 50.94, 51.25, 50.96, 51.04, 51.1, 50.79, 50.57, 51.65, 51.52, 51.48, 50.99, 50.96, 51.21, 51.28, 51.36, 51.81, 51.86, 51.21, 51.35, 51.59, 51.63, 51.48, 52.34, 52.11, 51.11, 51.42, 51.31, 51.48, 51.64, 50.9, 50.88, 50.76, 50.89, 51.82, 51.84, 52.03, 51.79, 51.9, 51.17, 51.82, 51.46, 51.37, 51.51, 51.3, 51.34, 51.27, 52.43, 50.9, 51.74, 51.98, 51.51, 52.0, 51.61, 51.7, 51.33, 51.02, 52.33, 52.19, 51.27, 51.7, 50.67, 51.73, 51.83, 51.67, 51.28, 52.09, 52.53, 51.97, 51.81, 51.56, 51.91]
train_loss_per_batch: []
